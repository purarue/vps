#!/usr/bin/env bash
# Backs up cache/credential/data files

set -u
set -o pipefail

# require that a executable be installed
require() {
	if [[ ! $(command -v "$1") ]]; then
		printf "requires %s, Install that and re-run\n" "$1"
		exit 1
	fi
}

# mkdir if first arg doesn't exist
mkdir_if_not_exists() {
	if [[ ! -d "$1" ]]; then
		mkdir -p "$1"
	fi
}

# make sure a file exists or exit
expect_file_and_copy() {
	if [[ ! -f "$1" ]]; then
		printf "Fatal error: Expected file at %s\n" "$1"
		exit 1
	fi
	cp "$1" "$2"
}

expect_dir_and_copy() {
	if [[ ! -d "$1" ]]; then
		printf "Fatal Error: no such directory %s\n" "$1"
		exit 1
	fi
	set +u
	if [[ -n "$2" ]]; then
		target="$BACKUP_DIR/$2"
		mkdir -p "$target"
		cp -R "$1" "$target" 2>/dev/null
	else
		cp -R "$1" "$BACKUP_DIR" 2>/dev/null
	fi
	set -u
}

optional_copy() {
	if [[ -f "$1" ]]; then
		cp "$1" "$2"
	else
		printf "Warning: Expected file at %s\n" "$1"
	fi
}

delete_if_exists() {
	[[ -d "$1" || -f "$1" ]] && rm -rf "$1" && printf "Removed '%s'\n" "$1"
}

require tar
require realpath

VPS_DIR="$(realpath "$(dirname "${BASH_SOURCE[0]}")/..")"
cd "$VPS_DIR" || exit $?
source "${VPS_DIR}/directories"

BACKUP_DIR_NAME="backup_dir"
BACKUP_DIR="${VPS_DIR}/${BACKUP_DIR_NAME}"
BACKUP_ENV_DIR="$BACKUP_DIR/env"

BACKUP_COUNTDOWN="${BACKUP_DIR}"/countdown
BACKUP_NOTIFY="${BACKUP_DIR}"/notify
BACKUP_TAR_NAME="${BACKUP_DIR_NAME}.tar.gz"

delete_if_exists "$BACKUP_DIR"
delete_if_exists "$BACKUP_TAR_NAME"

mkdir_if_not_exists "$BACKUP_COUNTDOWN"
mkdir_if_not_exists "$BACKUP_NOTIFY"
mkdir_if_not_exists "$BACKUP_ENV_DIR"

declare -A env_files=(
	["$HOME/.secrets/clipboard/.env"]="clipboard.env"
	["$HOME/.secrets/currently_listening/.env"]="currently_listening.env"
	["$HOME/.secrets/shorturl/.env"]="shorturl.env"
	["$HOME/code/filmswap/.env"]="filmswap.env"
	["$HOME/code/my_feed/backend/.env"]="my_feed_backend.env"
	["$HOME/code/checker_mal/.env"]="checker_mal.env"
	["$HOME/code/dbsentinel/.env"]="dbsentinel.env"
	["$HOME/code/dbsentinel/frontend/.env"]="dbsentinel_frontend.env"
	["$HOME/code/ttally_server/.env"]="ttally_server.env"
	["$HOME/code/exobrain/.env"]="exobrain.env"
	["$HOME/code/projects/.env"]="projects.env"
	["$HOME/code/glue/.env"]="glue.env"
)

# save data from my website
curl -s 'https://purarue.xyz/api/gb_comment' >"$BACKUP_DIR/gb_comment.json"
curl -s 'https://purarue.xyz/api/page_hit' >"$BACKUP_DIR/page_hit.json"

expect_file_and_copy "$NOTIFY_BOT/token.yaml" "$BACKUP_NOTIFY"
expect_file_and_copy "$NOTIFY_BOT/old" "$BACKUP_NOTIFY"
expect_file_and_copy "$NOTIFY_BOT/export.json" "$BACKUP_NOTIFY"
expect_file_and_copy "$COUNTDOWN_BOT/token.yaml" "$BACKUP_COUNTDOWN"
# Loop through each file and use expect_file_and_copy function
for src in "${!env_files[@]}"; do
	dest="$BACKUP_ENV_DIR/${env_files[$src]}"
	expect_file_and_copy "$src" "$dest"
done
optional_copy "$COUNTDOWN_BOT/server.db" "$BACKUP_COUNTDOWN"
optional_copy "$HOME/.bashrc" "$BACKUP_DIR"
optional_copy "$HOME/.bash_ext" "$BACKUP_DIR"
optional_copy "$HOME/.bash_profile" "$BACKUP_DIR"
optional_copy "$HOME/.bash_history" "$BACKUP_DIR"

fd . ~/code/ --type d | xargs -P 5 -I {} find {} -maxdepth 1 -name '.env' | rsync -vh --files-from=- / "$BACKUP_DIR"

expect_dir_and_copy "/etc/netdata"
expect_dir_and_copy "/etc/nginx"
expect_dir_and_copy "$HOME/shorturls"
expect_dir_and_copy "$CHECKER_MAL/data" checker_mal_data
expect_dir_and_copy "$GLUE/data/" glue_data
expect_dir_and_copy "$FILMSWAP/backups" filmswap_backups
expect_file_and_copy "$FILMSWAP/filmswap.db" "$BACKUP_DIR/filmswap_backups"

tar cvfz "$BACKUP_TAR_NAME" "$BACKUP_DIR_NAME" && printf "Created '%s'\n" "$BACKUP_TAR_NAME"
delete_if_exists "$BACKUP_DIR"
